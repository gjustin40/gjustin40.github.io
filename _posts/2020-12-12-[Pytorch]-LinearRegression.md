---
layout: post
title: "[Pytorch] - 선형회귀(Linear Regression)"
date: 2020-12-12 15:00:00
category: Pytorch
use_math: true
---

이전 포스터에서는 Tensor와 Autograd등에 대해 알아보았다. 이번 포스터에서는 Pytorch을 이용해 간단한 연산을 하는 방법에 대해 알아보고 선형회귀를 코드로 구현을 해서 어떤 원리가 적용되고 있는지, 또한 실제로 간단한 데이터를 생성하여 모델을 학습시켜 데이터에 맞는 적절한 모델을 찾는 실습을 해보기로 하자. 

# 선형 회귀(Linear Regression)
<hr>

일반적으로 사람 키와 몸무게는 서로 상관관계가 있다. 보통 키가 크면 몸무게도 많이 나갈 수 밖에 없다는 것을 잘 알고 있다. 물론 모든 사람에게 똑같이 적용되진 않지만, 선형회귀를 이해하기 위해 키와 몸무게의 관계가 비례관계에 있다고 가정을 해보자!

| 키(cm)   | 몸무게(kg) |
|----------|--------|
| 180 |  83     |
| 190 |  93     |
| 175 |  78     |
| 166 |  69     |
| 153 |  56     |

위 데이터를 통해 간단한 식을 설정하면 다음과 같다.

$$ 키(cm) = \theta_1\cdot 몸무게(kg) + \theta_0$$

이 모델은 입력 특성인 **몸무게(kg)** 에 대한 선형 함수이고 $\theta_0$과 $\theta_1$은 모델의 파라미터이다. 이처럼 키와 몸무게로 얻은 관계식을 '선형회귀모델'이라고 부른다. 이 식을 일반화하면 다음과 같다.

$$ y = \theta_0x_0 + \theta_1x_1  + \theta_2x_2  +\cdot\cdot\cdot\text{ }+ \theta_nx_n $$

위 식에서 $x_n$은 독립변수이며 $\theta_n$은 각 독립변수의 계수, $y$는 종속변수를 의미한다. 쉽게 x가 데이터(몸무게)가 되고, y는 그에 따른 예측값(키)가 되는 것이다. 이 식이 선형 회귀라고 불리는 이유는 종속변수가 독립변수에 대해 선형 함수(1차 함수)의 관계가 있을 것이라고 가정하기 때문이다.
- $x$는 독립변수 이외에 입력변수, 예측 변수, 독립 변수 등으로 불린다.
- $y$는 종속변수 이외에 응답변수라고도 불린다.
- $n$은 특성의 수로 독립변수의 종류를 뜻한다.(데이터의 개수와는 다른 의미이다.)







1차 함수가 바로 '회귀선(Regression Line)'이라고 부르고 다른 말로는 '단순선형회귀모델'이라고 부른다. 이것을 일반화하면 다음과 같다.

$$ y = \theta_1\cdot x + \theta_0$$

위 일반식에서 $x$를 '독립변수', $y$를 '종속변수'라고 부른다. 다시 말해 선형 회귀는 주어진 데이터의 집합에 대해 종속변수 $y$와 독립변수 $x$ 사이의 선형 관계를 모델링한다. 
<br>
선형 회귀에도 다양한 종류가 있지만, 크게 '단순 선형'과 '다중 선형'으로 나뉜다.

### 단순 선형 회귀
<br>
위에 언급한 '키와 몸무게'의 관계가 바로 단순선형회귀이다. 한 개의 스칼라 독립변수(몸무게)와 한 개의 스칼라 종속변수(키)의 관계를 말한다.

$$ y = \theta_1\cdot x + \theta_0$$


