---
layout: post
title: "[Pytorch] - 가중치 초기화(weight Initialization)"
date: 2021-01-07 19:00:00
category: Pytorch
use_math: true
---

오늘은 신경망 학습에서 중요한 요소 중 하나인 가중치(weight)의 초기화에 대해 알아보도록 하자.

# 가중치의 초깃값
<hr>

딥러닝이 막 사용되기 시작할 때는 초기값에 대한 관심이 별로 없었다. 초반에는 모델의 크기도 작았고 '딥러닝' 기술 자체에 관심을 가졌기 때문에 관심을 갖지 않았다. 하지만 모델이 커지고 깊어지면서 정확하고 빠르게 학습하기 위해서는 가중치의 초기값이 매우 중요하다는 사실이 밝혀지면서 많은 연구자들이 관심을 가지게 되었다. 

<br>

**가중치의 초깃값**이 중요한 이유는 다음과 같다.
- 부적절한 초깃값은 저조한 학습을 야기한다.
- 부적절한 초깃값은 과도한 학습시간을 야기한다.
- 딥러닝은 대부분 non-convex(볼록하지 않은 함수)하기 때문에 부적절한 초기값은 local minimum에 수렴하게 된다.

<br>

### 초깃값을 균일한 값으로 설정 시(ex. weight == 0)

<br>

만약 가중치의 모든 값이 전부 같으면 어떻게 될까? 모든 가중치값을 0으로 설정하고, 학습을 위해 오차역전파를 한다고 하자. 오차가 역으로 가면서 각 가중치마다 해당 오차에 대한 변화도를 계산하게 되는데, 모든 값이 동일하기 때문에 변화도 또한 동일한 값으로 계산이 되고, 결국 모든 값이 동일하게 갱신하게 된다. **모든 값이 동일하게 갱신된다면 가중치를 여러개 가지고 있는 의미가 사라지게 된다.** 따라서 이러한 문제를 해결하기 위해서서 가중치값은 반드시 '무작위"로 설정해야 한다.

